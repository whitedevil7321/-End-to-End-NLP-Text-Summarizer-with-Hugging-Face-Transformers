# ğŸ§  End-to-End NLP Text Summarizer with Hugging Face Transformers

This project is a complete, production-ready implementation of an **Abstractive Text Summarization System** using state-of-the-art Transformer models (like T5 or BART) from Hugging Face ğŸ¤—. It follows a modular pipeline structure with YAML-based configuration, custom logging, and stage-wise development inspired by a professional NLP workflow.

---

## ğŸ¯ Objective

To fine-tune a pretrained Transformer model for summarizing long text documents and expose it via an API for inference.

---

## ğŸ“¦ Features

- âœ… Logging and Utility Management
- âœ… Hugging Face Transformers-based fine-tuning
- âœ… Modular ML pipeline (Ingestion â†’ Transformation â†’ Training â†’ Evaluation â†’ Inference)
- âœ… FastAPI-based REST endpoint
- âœ… YAML-driven configuration
- âœ… Docker support for easy deployment
- âœ… Jupyter notebooks for experimentation

---

## ğŸ“‚ Project Structure

```
textsummarizer/
â”‚
â”œâ”€â”€ app.py                         # FastAPI app
â”œâ”€â”€ main.py                        # Entry point to run full pipeline
â”œâ”€â”€ Dockerfile                     # For containerization
â”œâ”€â”€ config/                        # YAML configuration files
â”œâ”€â”€ params.yaml                    # Model parameters
â”œâ”€â”€ setup.py                       # Installable package setup
â”œâ”€â”€ requirements.txt               # Project dependencies
â”œâ”€â”€ research/                      # Experiment notebooks
â”œâ”€â”€ src/textSummarizer/           # Core package
â”‚   â”œâ”€â”€ components/               # Data ingestion, transformation, trainer, evaluator
â”‚   â”œâ”€â”€ config/                   # Config parser
â”‚   â”œâ”€â”€ constants/                # Static global values
â”‚   â”œâ”€â”€ entity/                   # Data schemas
â”‚   â”œâ”€â”€ logging/                  # Custom logging setup
â”‚   â”œâ”€â”€ pipeline/                 # Stage-wise runner scripts
â”‚   â””â”€â”€ utils/                    # Helper functions
â””â”€â”€ README.md
```

---

## ğŸ§  Based On Course Sections

| Course Topic                                   | Implemented |
| ---------------------------------------------- | ----------- |
| 159. Intro to Hugging Face & Problem Statement | âœ…           |
| 160. GitHub Setup & Structure                  | âœ…           |
| 161. Logging and Utils                         | âœ…           |
| 162. Fine-tuning on Google Colab               | âœ…           |
| 163-164. Data Ingestion                        | âœ…           |
| 165. Data Transformation                       | âœ…           |
| 166. Model Trainer                             | âœ…           |
| 167. Model Evaluation                          | âœ…           |
| 168. Prediction + API Integration              | âœ…           |

---

## âš™ï¸ Installation

```bash
git clone https://github.com/yourusername/textsummarizer.git
cd textsummarizer
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### Run the full pipeline:

```bash
python main.py
```

### Launch API:

```bash
uvicorn app:app --reload
```

Open: `http://127.0.0.1:8000/docs` for Swagger UI.

---

## ğŸ³ Docker

Build and run using Docker:

```bash
docker build -t textsummarizer .
docker run -p 8000:8000 textsummarizer
```

---

## ğŸ§ª Jupyter Notebooks

Explore the `research/` directory for development steps:

- `1_data_ingestion.ipynb`
- `2_data_transformation.ipynb`
- `3_model_trainer.ipynb`
- `4_model_evaluation.ipynb`

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file.

---
s
## ğŸ‘¨â€ğŸ’» Author

Jeevan Aher

Masters of Science In computer ScienceÂ  Student\
University of Illinois Springfield\
[LinkedIn](https://www.linkedin.com/in/jeevanaher732/)
